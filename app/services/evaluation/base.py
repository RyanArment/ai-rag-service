"""
Base evaluation framework for RAG systems.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from datetime import datetime


class EvaluationResult(BaseModel):
    """Result of a single evaluation metric."""
    metric_name: str
    score: float
    details: Optional[Dict[str, Any]] = None
    timestamp: datetime = Field(default_factory=datetime.utcnow)


class EvaluationReport(BaseModel):
    """Complete evaluation report."""
    evaluation_id: str
    test_set_name: str
    total_questions: int
    results: List[EvaluationResult]
    overall_score: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None
    timestamp: datetime = Field(default_factory=datetime.utcnow)


class BaseEvaluator(ABC):
    """Base class for evaluation metrics."""
    
    @abstractmethod
    def evaluate(
        self,
        question: str,
        expected_answer: Optional[str],
        actual_answer: str,
        context: Optional[List[str]] = None,
    ) -> EvaluationResult:
        """
        Evaluate a single Q&A pair.
        
        Args:
            question: The question asked
            expected_answer: Expected/gold standard answer (optional)
            actual_answer: The answer generated by the system
            context: Context chunks used (optional)
            
        Returns:
            EvaluationResult with score and details
        """
        pass
    
    @abstractmethod
    def get_metric_name(self) -> str:
        """Return the name of this metric."""
        pass
